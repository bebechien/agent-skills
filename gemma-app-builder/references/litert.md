# LiteRT-LM

Formerly TensorFlow Lite for LLMs. Optimized for on-device performance (Android, iOS, Web).

**Setup:**
-   **Convert**: Convert the Gemma checkpoint to `.tflite` format using the LiteRT converter.
-   **Integrate**: Use the LiteRT-LM C++ or Java API to load the model and run inference.
-   **Performance**: Leverages GPU and NPU acceleration.

**Example Prompt:**
"How do I convert a Gemma model to .tflite for use with LiteRT-LM?"
