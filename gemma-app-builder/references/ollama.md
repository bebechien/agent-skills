# Ollama

Ollama is a lightweight tool to run LLMs locally.

**Setup:**
-   **Install**: Download from [ollama.com](https://ollama.com).
-   **Pull Gemma**: `ollama pull gemma3:1b`
-   **Run**: `ollama run gemma3:1b`
-   **API**: Runs on `http://localhost:11434`.

**Example Prompt:**
"Show me how to run Gemma with Ollama and access the API."
