# LM Studio

LM Studio provides a GUI for discovering and running local LLMs.

**Setup:**
-   **Install**: Download from [lmstudio.ai](https://lmstudio.ai).
-   **Search**: Find "Gemma" in the search bar.
-   **Download**: Select a quantization level and download.
-   **Serve**: Go to the "Local Server" tab and start the server.
-   **API**: Compatible with OpenAI's API format.

**Example Prompt:**
"How do I load Gemma in LM Studio and start the local server?"
